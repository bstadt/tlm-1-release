{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aafcfdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-11 21:59:15.013195: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-11 21:59:15.032843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757627955.057808   95940 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757627955.065919   95940 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757627955.085024   95940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757627955.085046   95940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757627955.085050   95940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757627955.085052   95940 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-11 21:59:15.091165: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "# Load the saved model and tokenizer\n",
    "loadstr = '/home/ubuntu/tlm-files/tlm/models/tlm-2025-08-05_16-42-11/checkpoint-10500/'\n",
    "model = AutoModelForMaskedLM.from_pretrained(loadstr)\n",
    "#tokenizer = BertTokenizerFast.from_pretrained('../coca_tokenized/tokenizer/')\n",
    "tokenizer = AutoTokenizer.from_pretrained(loadstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c52d33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def l_fill(phrase, fill, model, tokenizer):\n",
    "    model.eval()\n",
    "\n",
    "    target_ids = tokenizer.encode(fill, add_special_tokens=False)\n",
    "    years = list(range(1990, 2020))\n",
    "    yearly_fill_probs = []\n",
    "    \n",
    "    for year in years:\n",
    "        temporal_phrase = '[YEAR:{}]'.format(year) + phrase\n",
    "        with torch.no_grad():\n",
    "            input_ids = tokenizer.encode(temporal_phrase, add_special_tokens=False, return_tensors='pt')\n",
    "            mask_locs = torch.where(input_ids==tokenizer.mask_token_id)\n",
    "            num_masks = len(mask_locs[0])\n",
    "            if num_masks != len(target_ids):\n",
    "                raise ValueError('Tring to fill {} masks with {} tokens'.format(num_masks, len(target_ids)))\n",
    "\n",
    "            outputs = model(input_ids=input_ids)\n",
    "            fill_logits = outputs.logits[mask_locs]\n",
    "            fill_probs = F.softmax(fill_logits, dim=-1)\n",
    "\n",
    "            cur_fill_probs = []\n",
    "            for mask_idx, target_id in enumerate(target_ids):\n",
    "                cur_fill_probs.append(fill_probs[mask_idx, target_id])\n",
    "            yearly_fill_probs.append(cur_fill_probs)\n",
    "\n",
    "    return years, yearly_fill_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fc97fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def l_fills(phrase, fills, model, tokenizer):\n",
    "    model.eval()\n",
    "\n",
    "    fill_target_ids = [tokenizer.encode(fill, add_special_tokens=False) for fill in fills]\n",
    "    years = list(range(1990, 2020))\n",
    "    yearly_fill_probs = []\n",
    "    \n",
    "    for year in years:\n",
    "        temporal_phrase = '[YEAR:{}]'.format(year) + phrase\n",
    "        with torch.no_grad():\n",
    "            input_ids = tokenizer.encode(temporal_phrase, add_special_tokens=False, return_tensors='pt')\n",
    "            mask_locs = torch.where(input_ids==tokenizer.mask_token_id)\n",
    "\n",
    "            outputs = model(input_ids=input_ids)\n",
    "            fill_logits = outputs.logits[mask_locs]\n",
    "            fill_sublogits = fill_logits[:, fill_target_ids][0]\n",
    "            cur_fill_probs = F.softmax(fill_sublogits, dim=0)\n",
    "\n",
    "            yearly_fill_probs.append(cur_fill_probs)\n",
    "\n",
    "    return years, yearly_fill_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d355a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for dimension 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_95940/2367393238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'president [mask] made a speech today'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myears\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_fills\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'trump'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'obama'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfill_probs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'trump'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_95940/4174827195.py\u001b[0m in \u001b[0;36ml_fills\u001b[0;34m(phrase, fills, model, tokenizer)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mfill_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mfill_sublogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_logits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_target_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mcur_fill_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_sublogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for dimension 0 with size 0"
     ]
    }
   ],
   "source": [
    "template = 'president [mask] made a speech today'\n",
    "years, fill_probs = l_fills(template, ['trump', 'obama'], model, tokenizer)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(years, [e[0] for e in fill_probs], label='trump')\n",
    "plt.plot(years, [e[1] for e in fill_probs], label='obama')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a135cc8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
